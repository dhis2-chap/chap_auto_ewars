R_star_list <- Scaled_structure_matrices_for_ARW1(N, conf_years)
ARW1_model <- inla.rgeneric.define(inla.rgeneric.AdaptiveRW1.model,
N = N, R_star_list = R_star_list)
# Chunk 19
inla.rgeneric.AdaptiveRW1.model2 = function(
cmd = c("graph", "Q", "mu", "initial", "log.norm.const","log.prior", "quit"),
theta = NULL)
{
#Input:
#N is the number of timepoints
#conflict_years
#prior_str is either Gamma0.005, Gamma0.00005 or PC
envir = parent.env(environment())
interpret_theta <- function() { return(list(tau1 = exp(theta[1L]),
tau2 = exp(theta[2L])))}
graph <- function() {return(Q())}
Q <- function() {
R1 <- matrix(0, nrow = N, ncol = N) #non-conflict
R2 <- matrix(0, nrow = N, ncol = N) #conflict
for( i in 1:(N - 1)){
if(i %in% conflict_years | (i + 1) %in% conflict_years) {
R2[c(i, i+1), c(i, i+1)] <- R2[c(i, i+1), c(i, i+1)] + c(1, -1, -1, 1)
}
else {
R1[c(i, i+1), c(i, i+1)] <- R1[c(i, i+1), c(i, i+1)] + c(1, -1, -1, 1)
}
}
gv <- exp(1 / N * sum(log(diag(INLA:::inla.ginv(R1 + R2))))) #scaling constant
R_star_list <- list(R1 = R1*gv, R2 = R2*gv)
p <- interpret_theta()
Q <- R_star_list$R1 * p$tau1 + R_star_list$R2 * p$tau2
return(inla.as.sparse(Q)) #sparse representation
}
mu <- function() {return(numeric(0))}
initial <- function() {return(c(4, 4))}#Default initial for precisions is 4
log.norm.const <- function() {return(numeric(0))}
log.prior <- function() {#default: shape = 1, rate = 0.00005
p <- interpret_theta()
if(prior_str == "PC"){
prior <- inla.pc.dprec(p$tau1, u = 1, alpha = 0.01, log=TRUE) + log(p$tau1) +
inla.pc.dprec(p$tau2, u = 1, alpha = 0.01, log = TRUE) + log(p$tau2)
return(prior)
} else if(prior_str == "Gamma0,005"){
prior <- dgamma(p$tau1, shape = 1, rate = 0.005, log = TRUE) + log(p$tau1) +
dgamma(p$tau2, shape = 1, rate = 0.005, log = TRUE) + log(p$tau2)
return(prior)
}
prior <- dgamma(p$tau1, shape = 1, rate = 0.00005, log = TRUE) + log(p$tau1) +
dgamma(p$tau2, shape = 1, rate = 0.00005, log = TRUE) + log(p$tau2)
return(prior)
}
quit <- function() {return(invisible())}
#to ensure theta is defined
if (!length(theta)) theta = initial()
vals <- do.call(match.arg(cmd), args = list())
return(vals)
}
# Chunk 21
RMSE <- function(data, preds){
return(sqrt( sum((data - preds)**2) / length(data))) #definition of RMSE
}
# Chunk 25
#parameters
N <- 30 #number of timepoints
n <- 100 #number of simulations in each case
conf_years <- c(9, 10, 11, 12, 13, 14, 15) #the conflict years
#defining the means
mean_flat <- rep(2, N)
mean_delta <- mean_flat + c(rep(0, 8), rep(1, 7), rep(0, 15))
mean_triangle <- mean_flat + c(rep(0, 8), c(0.3, 0.6, 0.9, 1.2,
0.9, 0.6, 0.3), rep(0, 15))
#visualizing the means
df <- data.frame(matrix(c(mean_flat, mean_delta, mean_triangle, 1:N), ncol = 4, nrow = N))
plot_flat <- ggplot(df, aes(x = X4, y = X1)) + geom_line() +
labs(title="Flat", y="Mean", x = "") + ylim(2, 3.25)
plot_delta <- ggplot(df, aes(x = X4, y = X2)) + geom_line() +
labs(title="Delta", x="t", y = "") + ylim(2, 3.25)
plot_triangle <- ggplot(df, aes(x = X4, y = X3)) + geom_line() + labs(title="Triangle", x = "", y = "") + ylim(2, 3.25)
ggarrange(plot_flat, plot_delta, plot_triangle, nrow = 1, ncol = 3)
# Chunk 26
#functions to simulate data as in Wakefield and Aleshin-Guendel
sim_data_Wakefield <- function(mu, V, tau1 = 20, tau2 = 20) {
eta <- mu + c(rnorm(8, sd = sqrt(1/tau1)), rnorm(7, sd = sqrt(1/tau2)),
rnorm(15, sd = sqrt(1/tau1)))
y <- rnorm(length(mu), mean = eta, sd = sqrt(V))
return(list(y, eta)) #[[1]] gives y and [[2]] gives eta
}
sim_dataframe_Wakefield <- function(n, mu, V, tau1 = 20, tau2 = 20, seed = 64) {
set.seed(seed)
mean_str <- strsplit(deparse(substitute(mu)), split = "_", fixed = TRUE)[[1]][2]
V_str <- toString(as.integer(1/V))
if(tau1 == tau2) {
T_str <- "CT"
}
else{
T_str <- "NCT"
}
df_y <- data.frame(matrix(0, nrow = length(mu), ncol = n))
df_eta <- data.frame(matrix(0, nrow = length(mu), ncol = n))
for (i in 1:n) {
sim_data <- sim_data_Wakefield(mu, V, tau1 = tau1, tau2 = tau2)
df_y[, i] <- sim_data[[1]]
df_eta[, i] <- sim_data[[2]]
}
df_y$t <- 1:length(mu)
df_y$us <- 1:length(mu)
data_W <- list(df_y, df_eta)
save(data_W, file = paste0("C:/Users/Halvard/Documents/GitHub/Master-project/Wakefield-data/Data_W/data_W_", mean_str, "_", V_str, "_", T_str))
return(data_W)
}
# Chunk 27
#for constant tau (CT)
# flat mean with varying V
data_w_flat_75_CT <- sim_dataframe_Wakefield(n, mean_flat, 1/75)
data_w_flat_150_CT <- sim_dataframe_Wakefield(n, mean_flat, 1/150)
data_w_flat_300_CT <- sim_dataframe_Wakefield(n, mean_flat, 1/300)
#delta mean with varying V
data_w_delta_75_CT <- sim_dataframe_Wakefield(n, mean_delta, 1/75)
data_w_delta_150_CT <- sim_dataframe_Wakefield(n, mean_delta, 1/150)
data_w_delta_300_CT <- sim_dataframe_Wakefield(n, mean_delta, 1/300)
#triangle mean with varying V
data_w_triangle_75_CT <- sim_dataframe_Wakefield(n, mean_triangle, 1/75)
data_w_triangle_150_CT <- sim_dataframe_Wakefield(n, mean_triangle, 1/150)
data_w_triangle_300_CT <- sim_dataframe_Wakefield(n, mean_triangle, 1/300)
#for non-constant tau (NCT)
# flat mean with varying V
data_w_flat_75_NCT <- sim_dataframe_Wakefield(n, mean_flat, 1/75, tau2 = 10)
data_w_flat_150_NCT <- sim_dataframe_Wakefield(n, mean_flat, 1/150, tau2 = 10)
data_w_flat_300_NCT <- sim_dataframe_Wakefield(n, mean_flat, 1/300, tau2 = 10)
#delta mean with varying V
data_w_delta_75_NCT <- sim_dataframe_Wakefield(n, mean_delta, 1/75, tau2 = 10)
data_w_delta_150_NCT <- sim_dataframe_Wakefield(n, mean_delta, 1/150, tau2 = 10)
data_w_delta_300_NCT <- sim_dataframe_Wakefield(n, mean_delta, 1/300, tau2 = 10)
#triangle mean with varying V
data_w_triangle_75_NCT <- sim_dataframe_Wakefield(n, mean_triangle, 1/75, tau2 = 10)
data_w_triangle_150_NCT <- sim_dataframe_Wakefield(n, mean_triangle, 1/150, tau2 = 10)
data_w_triangle_300_NCT <- sim_dataframe_Wakefield(n, mean_triangle, 1/300, tau2 = 10)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
N <- 30
conf_years <- c(9, 10, 11, 12, 13, 14, 15)
prior_str <- "Gamma0,005" #other alternatives are Gamma0,005 and Gamma0,00005 and PC
if(prior_str == "Gamma0,00005"){
formula_RW1 <- y ~ f(time, model = "rw1", scale.model = T)  + f(us, model = "iid")
} else if(prior_str == "Gamma0,005"){
formula_RW1 <- y ~ f(time, model = "rw1", scale.model = T, hyper = list(prec = list(prior = "loggamma", param = c(1, 0.005))))  + f(us, model = "iid")
} else{
formula_RW1 <- y ~ f(time, model = "rw1", scale.model = T, hyper = list(prec = list(prior = "pc.prec", param = c(1, 0.01))))  + f(us, model = "iid")
}
ARW1_model <- inla.rgeneric.define(inla.rgeneric.AdaptiveRW1.model2, N = N, conflict_years = conf_years, prior_str = prior_str)
formula_ARW1_W <- y ~ f(time, model = ARW1_model,
extraconstr = list(A = matrix(1, nrow = 1, ncol = N), e = 0)) +
f(us, model = "iid")
mod_eval_W <- function(df, mean = "", V = "", P, tau = "") {
df_y <- df[[1]]
df_eta <- df[[2]]
n <- dim(df_y)[2] - 2
eval_df <- data.frame(matrix(NA, nrow = n, ncol = 4))
colnames(eval_df) <- c("RMSE_RW1", "LS_RW1", "RMSE_ARW1", "LS_ARW1")
for(i in 1:n){#iterate over each simulated realization
test_data <- df_y[, c(i, n + 1, n + 2)] #gets the i-th realization + time
colnames(test_data) <- c("y", "time", "us") #makes the colnames match the formula
res_RW1 <- inla(formula_RW1, family = "gaussian", data = test_data,
control.compute = list(cpo = TRUE),
control.family = list(hyper = list(prec =
list(initial = log(P), fixed = TRUE))))
LS_RW1 <- -mean(log(res_RW1$cpo$cpo))
RMSE_RW1 <- RMSE(df_eta[, i], res_RW1$summary.fitted.values$mean)
res_ARW1 <- inla(formula_ARW1_W, family = "gaussian", data = test_data,
control.compute = list(cpo = TRUE),
control.family = list(hyper = list(prec =
list(initial = log(P), fixed = TRUE))))
LS_ARW1 <- -mean(log(res_ARW1$cpo$cpo))
RMSE_ARW1 <- RMSE(df_eta[, i], res_ARW1$summary.fitted.values$mean)
eval_df[i, ] <- c(RMSE_RW1, LS_RW1, RMSE_ARW1, LS_ARW1)
}
save(eval_df, file=paste0("C:/Users/Halvard/Documents/GitHub/Master-project/Wakefield-data/", prior_str, "/Results3/eval_df_", mean, "_", P, "_", tau))
#save(eval_df, file=paste0("C:/Users/Halvard/Documents/GitHub/Master-project/Harmonius-data/", prior_str, "/eval_df_", mean, "_", P, "_", tau))
return()
}
d_300_NCT <- mod_eval_W(data_w_delta_300_NCT, "delta", "1/300", 300, "NCT")
t_75_NCT <- mod_eval_W(data_w_triangle_75_NCT, "triangle", "1/75", 75, "NCT")
t_150_NCT <- mod_eval_W(data_w_triangle_150_NCT, "triangle", "1/150", 150, "NCT")
t_300_NCT <- mod_eval_W(data_w_triangle_300_NCT, "triangle", "1/300", 300, "NCT")
#splicing the eval df's together to one with sensible column names
means <- c("flat", "delta", "triangle")
precs <- c("75", "150", "300")
taus <- c("CT", "NCT")
for(m in 1:length(means)){
for(p in 1:length(precs)){
for(t in 1:length(taus)){
load(paste0("C:/Users/Halvard/Documents/GitHub/Master-project/Wakefield-data/", prior_str, "/Results3/eval_df_", means[m], "_", precs[p], "_", taus[t]))
index_str <- paste0("_", means[m], "_", precs[p], "_", taus[t])
colnames(eval_df) <- c(paste0("RMSE_RW1", index_str), paste0("LS_RW1", index_str), paste0("RMSE_ARW1", index_str), paste0("LS_ARW1", index_str))
if(m == 1 & p == 1 & t == 1){
full_eval_df <- eval_df
}
else{
full_eval_df <- cbind(full_eval_df, eval_df)
}
}
}
}
save(full_eval_df, file=paste0("C:/Users/Halvard/Documents/GitHub/Master-project/Wakefield-data/", prior_str,"/Results3/full_eval_df"))
library(ggpubr) #for plotlist in ggarrange
library(grid)
box_plot_eval <- function(df, mean, P, ymin, ymax, x_text_bool){
colnames(df) <- c("RW1", "ARW1")
# Reshape data to long format
df_long <- df %>%
pivot_longer(cols = everything(), names_to = "Category", values_to = "Value")
# Create the boxplot
eval_plot <- ggplot(df_long, aes(x = Category, y = Value, fill = Category)) +
geom_boxplot() +
ggtitle(paste0("Mu: ", mean, ", V: 1/", P)) + xlab("") + ylab("") +
ylim(ymin, ymax) +
scale_fill_manual(values = c("RW1" = "skyblue", "ARW1" = "orange")) +
theme(legend.position ="none") +
if(x_text_bool){theme()}
else{theme(axis.text.x = element_blank())}
return(eval_plot)
}
make_full_box_plot <- function(df, criteria, tau, prior){
#Input: df is a full_eval_df, criteria is either "RMSE" or "LS" while tau is either "CT" or "NCT"
# and prior is the specific prior for the precision
if(prior == "Gamma0,00005"){prior_name <- "Gamma(1, 0.00005)"}
else if(prior == "Gamma0,005"){prior_name <- "Gamma(1, 0.005)"}
else{prior_name <- "PC(1, 0.01)"}
precs <- c("75", "150", "300")
means <- c("flat", "delta", "triangle")
plot_list <- list()
x_text_bool <- FALSE
for(m in 1:length(means)){
if(m == length(means)){x_text_bool <- TRUE} #decides if the x_text shows or not
RW1_str <- paste0(criteria, "_RW1_", means[m], "_") #needs "P_tau"
ARW1_str <- paste0(criteria, "_ARW1_", means[m], "_") #needs "P_tau"
df_exempt <- df[, c(paste0(RW1_str, precs[1], "_", tau), paste0(RW1_str, precs[2], "_", tau), paste0(RW1_str, precs[3], "_", tau), paste0(ARW1_str, precs[1], "_", tau), paste0(ARW1_str, precs[2], "_", tau), paste0(ARW1_str, precs[3], "_", tau))] #the relevant columns of df
#Find the min and max value to enforce the same y-axis for the same mean
ymax <- max(df_exempt)
ymin <- min(df_exempt)
for(p in 1:length(precs)){
plot_list[[(m-1)*3 + p]] <- box_plot_eval(df_exempt[, c(p, p +
length(precs))],means[m], precs[p], ymin, ymax, x_text_bool)
}
}
plot <- ggarrange(plotlist = plot_list, ncol = 3, nrow = 3)
#making the title
title <- paste0(criteria, " for Wakefield data with ")
if(tau == "CT"){title <- paste0(title, "constant tau and ")}
else{title <- paste0(title, "non-constant tau and ")}
title <- paste0(title, prior_name)
plot_w_title <- annotate_figure(plot, top = textGrob(title, gp = (gpar(fontsize = 17))))
ggsave(filename = paste0("C:/Users/Halvard/Documents/GitHub/Master-project/Box-plots2/", criteria, "_", tau, "_", prior, ".pdf"), plot = plot_w_title, width = 8, height = 7, units = "in")
return(plot_w_title)
}
make_full_box_plot(full_eval_df, "RMSE", "CT", "Gamma0,005")
make_full_box_plot(full_eval_df, "LS", "CT", "Gamma0,005")
make_full_box_plot(full_eval_df, "RMSE", "NCT", "Gamma0,005")
make_full_box_plot(full_eval_df, "LS", "NCT", "Gamma0,005")
N <- 30
conf_years <- c(9, 10, 11, 12, 13, 14, 15)
prior_str <- "PC" #other alternatives are Gamma0,005 and Gamma0,00005 and PC
if(prior_str == "Gamma0,00005"){
formula_RW1 <- y ~ f(time, model = "rw1", scale.model = T)  + f(us, model = "iid")
} else if(prior_str == "Gamma0,005"){
formula_RW1 <- y ~ f(time, model = "rw1", scale.model = T, hyper = list(prec = list(prior = "loggamma", param = c(1, 0.005))))  + f(us, model = "iid")
} else{
formula_RW1 <- y ~ f(time, model = "rw1", scale.model = T, hyper = list(prec = list(prior = "pc.prec", param = c(1, 0.01))))  + f(us, model = "iid")
}
ARW1_model <- inla.rgeneric.define(inla.rgeneric.AdaptiveRW1.model2, N = N, conflict_years = conf_years, prior_str = prior_str)
formula_ARW1_W <- y ~ f(time, model = ARW1_model,
extraconstr = list(A = matrix(1, nrow = 1, ncol = N), e = 0)) +
f(us, model = "iid")
mod_eval_W <- function(df, mean = "", V = "", P, tau = "") {
df_y <- df[[1]]
df_eta <- df[[2]]
n <- dim(df_y)[2] - 2
eval_df <- data.frame(matrix(NA, nrow = n, ncol = 4))
colnames(eval_df) <- c("RMSE_RW1", "LS_RW1", "RMSE_ARW1", "LS_ARW1")
for(i in 1:n){#iterate over each simulated realization
test_data <- df_y[, c(i, n + 1, n + 2)] #gets the i-th realization + time
colnames(test_data) <- c("y", "time", "us") #makes the colnames match the formula
res_RW1 <- inla(formula_RW1, family = "gaussian", data = test_data,
control.compute = list(cpo = TRUE),
control.family = list(hyper = list(prec =
list(initial = log(P), fixed = TRUE))))
LS_RW1 <- -mean(log(res_RW1$cpo$cpo))
RMSE_RW1 <- RMSE(df_eta[, i], res_RW1$summary.fitted.values$mean)
res_ARW1 <- inla(formula_ARW1_W, family = "gaussian", data = test_data,
control.compute = list(cpo = TRUE),
control.family = list(hyper = list(prec =
list(initial = log(P), fixed = TRUE))))
LS_ARW1 <- -mean(log(res_ARW1$cpo$cpo))
RMSE_ARW1 <- RMSE(df_eta[, i], res_ARW1$summary.fitted.values$mean)
eval_df[i, ] <- c(RMSE_RW1, LS_RW1, RMSE_ARW1, LS_ARW1)
}
save(eval_df, file=paste0("C:/Users/Halvard/Documents/GitHub/Master-project/Wakefield-data/", prior_str, "/Results3/eval_df_", mean, "_", P, "_", tau))
#save(eval_df, file=paste0("C:/Users/Halvard/Documents/GitHub/Master-project/Harmonius-data/", prior_str, "/eval_df_", mean, "_", P, "_", tau))
return()
}
f_75_CT <- mod_eval_W(data_w_flat_75_CT, "flat", "1/75", 75, "CT")
f_150_CT <- mod_eval_W(data_w_flat_150_CT, "flat", "1/150", 150, "CT")
f_300_CT <- mod_eval_W(data_w_flat_300_CT, "flat", "1/300", 300, "CT")
d_75_CT <- mod_eval_W(data_w_delta_75_CT, "delta", "1/75", 75, "CT")
d_150_CT <- mod_eval_W(data_w_delta_150_CT, "delta", "1/150", 150, "CT")
d_300_CT <- mod_eval_W(data_w_delta_300_CT, "delta", "1/300", 300, "CT")
t_75_CT <- mod_eval_W(data_w_triangle_75_CT, "triangle", "1/75", 75, "CT")
t_150_CT <- mod_eval_W(data_w_triangle_150_CT, "triangle", "1/150", 150, "CT")
t_300_CT <- mod_eval_W(data_w_triangle_300_CT, "triangle", "1/300", 300, "CT")
#Data with non-constant tau
f_75_NCT <- mod_eval_W(data_w_flat_75_NCT, "flat", "1/75", 75, "NCT")
f_150_NCT <- mod_eval_W(data_w_flat_150_NCT, "flat", "1/150", 150, "NCT")
f_300_NCT <- mod_eval_W(data_w_flat_300_NCT, "flat", "1/300", 300, "NCT")
d_75_NCT <- mod_eval_W(data_w_delta_75_NCT, "delta", "1/75", 75, "NCT")
d_150_NCT <- mod_eval_W(data_w_delta_150_NCT, "delta", "1/150", 150, "NCT")
d_300_NCT <- mod_eval_W(data_w_delta_300_NCT, "delta", "1/300", 300, "NCT")
t_75_NCT <- mod_eval_W(data_w_triangle_75_NCT, "triangle", "1/75", 75, "NCT")
t_150_NCT <- mod_eval_W(data_w_triangle_150_NCT, "triangle", "1/150", 150, "NCT")
t_300_NCT <- mod_eval_W(data_w_triangle_300_NCT, "triangle", "1/300", 300, "NCT")
#splicing the eval df's together to one with sensible column names
means <- c("flat", "delta", "triangle")
precs <- c("75", "150", "300")
taus <- c("CT", "NCT")
for(m in 1:length(means)){
for(p in 1:length(precs)){
for(t in 1:length(taus)){
load(paste0("C:/Users/Halvard/Documents/GitHub/Master-project/Wakefield-data/", prior_str, "/Results3/eval_df_", means[m], "_", precs[p], "_", taus[t]))
index_str <- paste0("_", means[m], "_", precs[p], "_", taus[t])
colnames(eval_df) <- c(paste0("RMSE_RW1", index_str), paste0("LS_RW1", index_str), paste0("RMSE_ARW1", index_str), paste0("LS_ARW1", index_str))
if(m == 1 & p == 1 & t == 1){
full_eval_df <- eval_df
}
else{
full_eval_df <- cbind(full_eval_df, eval_df)
}
}
}
}
save(full_eval_df, file=paste0("C:/Users/Halvard/Documents/GitHub/Master-project/Wakefield-data/", prior_str,"/Results3/full_eval_df"))
library(ggpubr) #for plotlist in ggarrange
library(grid)
box_plot_eval <- function(df, mean, P, ymin, ymax, x_text_bool){
colnames(df) <- c("RW1", "ARW1")
# Reshape data to long format
df_long <- df %>%
pivot_longer(cols = everything(), names_to = "Category", values_to = "Value")
# Create the boxplot
eval_plot <- ggplot(df_long, aes(x = Category, y = Value, fill = Category)) +
geom_boxplot() +
ggtitle(paste0("Mu: ", mean, ", V: 1/", P)) + xlab("") + ylab("") +
ylim(ymin, ymax) +
scale_fill_manual(values = c("RW1" = "skyblue", "ARW1" = "orange")) +
theme(legend.position ="none") +
if(x_text_bool){theme()}
else{theme(axis.text.x = element_blank())}
return(eval_plot)
}
make_full_box_plot <- function(df, criteria, tau, prior){
#Input: df is a full_eval_df, criteria is either "RMSE" or "LS" while tau is either "CT" or "NCT"
# and prior is the specific prior for the precision
if(prior == "Gamma0,00005"){prior_name <- "Gamma(1, 0.00005)"}
else if(prior == "Gamma0,005"){prior_name <- "Gamma(1, 0.005)"}
else{prior_name <- "PC(1, 0.01)"}
precs <- c("75", "150", "300")
means <- c("flat", "delta", "triangle")
plot_list <- list()
x_text_bool <- FALSE
for(m in 1:length(means)){
if(m == length(means)){x_text_bool <- TRUE} #decides if the x_text shows or not
RW1_str <- paste0(criteria, "_RW1_", means[m], "_") #needs "P_tau"
ARW1_str <- paste0(criteria, "_ARW1_", means[m], "_") #needs "P_tau"
df_exempt <- df[, c(paste0(RW1_str, precs[1], "_", tau), paste0(RW1_str, precs[2], "_", tau), paste0(RW1_str, precs[3], "_", tau), paste0(ARW1_str, precs[1], "_", tau), paste0(ARW1_str, precs[2], "_", tau), paste0(ARW1_str, precs[3], "_", tau))] #the relevant columns of df
#Find the min and max value to enforce the same y-axis for the same mean
ymax <- max(df_exempt)
ymin <- min(df_exempt)
for(p in 1:length(precs)){
plot_list[[(m-1)*3 + p]] <- box_plot_eval(df_exempt[, c(p, p +
length(precs))],means[m], precs[p], ymin, ymax, x_text_bool)
}
}
plot <- ggarrange(plotlist = plot_list, ncol = 3, nrow = 3)
#making the title
title <- paste0(criteria, " for Wakefield data with ")
if(tau == "CT"){title <- paste0(title, "constant tau and ")}
else{title <- paste0(title, "non-constant tau and ")}
title <- paste0(title, prior_name)
plot_w_title <- annotate_figure(plot, top = textGrob(title, gp = (gpar(fontsize = 17))))
ggsave(filename = paste0("C:/Users/Halvard/Documents/GitHub/Master-project/Box-plots2/", criteria, "_", tau, "_", prior, ".pdf"), plot = plot_w_title, width = 8, height = 7, units = "in")
return(plot_w_title)
}
make_full_box_plot(full_eval_df, "RMSE", "CT", "PC")
make_full_box_plot(full_eval_df, "LS", "CT", "PC")
make_full_box_plot(full_eval_df, "RMSE", "NCT", "PC")
make_full_box_plot(full_eval_df, "LS", "NCT", "PC")
library(INLA)
INLA:::inla.doc("bym2")
library(INLA)
library(dlnm)
library(dplyr)
#for spatial effects
library(sf)
library(spdep)
setwd("C:/Users/Halvard/Documents/GitHub/chap_auto_ewars")
# testing
library(dplyr)
model_fn <- "model"
hist_fn <- "example_data_Viet/historic_data.csv"
future_fn <- "example_data_Viet/future_data.csv"
preds_fn <- "example_data_Viet/predictions.csv"
graph_fn <- "example_data_Viet/vietnam.json"
geojson <- st_read(graph_fn)
geojson <- st_make_valid(geojson)
#might also need to alphabetically sort both geojson after location and the
# dataframe after location!
df <- read.csv(future_fn)
df_locs <- unique(df$location)
geojson$VARNAME_1
nb <- poly2nb(geojson, queen = TRUE) #adjacent polygons are neighbors
adjacency <- nb2mat(nb, style = "B", zero.policy = TRUE)
geojson_reduced <- geojson[geojson$VARNAME_1 %in% df_locs, ]
nb_red <- poly2nb(geojson_reduced, queen = TRUE) #adjacent polygons are neighbors
adjacency_red <- nb2mat(nb_red, style = "B", zero.policy = TRUE)
row.names(adjacency_red) <- NULL
image(adjacency_red)
#plot of Vietnam for all the regions
plot(st_geometry(geojson),
col = "steelblue", lwd = 0.5, asp = 1)
#plot of the regions of Vietnam in the training data
plot(st_geometry(geojson_red),
col = "steelblue", lwd = 0.5, asp = 1)
#plot of the regions of Vietnam in the training data
plot(st_geometry(geojson_reduced),
col = "steelblue", lwd = 0.5, asp = 1)
graph_fn <- "brazil_polygons.geojson"
future_fn <- "brazil.csv"
df <- read.csv(future_fn)
df_locs <- unique(df$location)
geojson <- st_read(graph_fn)
geojson <- st_make_valid(geojson)
geojson$VARNAME_1
nb <- poly2nb(geojson, queen = TRUE) #adjacent polygons are neighbors
adjacency <- nb2mat(nb, style = "B", zero.policy = TRUE)
geojson_reduced <- geojson[geojson$VARNAME_1 %in% df_locs, ]
nb_red <- poly2nb(geojson_reduced, queen = TRUE) #adjacent polygons are neighbors
adjacency_red <- nb2mat(nb_red, style = "B", zero.policy = TRUE)
row.names(adjacency_red) <- NULL
image(adjacency_red)
#plot of Vietnam for all the regions
plot(st_geometry(geojson),
col = "steelblue", lwd = 0.5, asp = 1)
#plot of the regions of Vietnam in the training data
plot(st_geometry(geojson_reduced),
col = "steelblue", lwd = 0.5, asp = 1)
geojson <- st_read(graph_fn)
View(geojson)
geojson <- st_make_valid(geojson)
geojson$VARNAME_1
geojson$NAME
nb <- poly2nb(geojson, queen = TRUE) #adjacent polygons are neighbors
adjacency <- nb2mat(nb, style = "B", zero.policy = TRUE)
geojson_reduced <- geojson[geojson$NAME %in% df_locs, ]
nb_red <- poly2nb(geojson_reduced, queen = TRUE) #adjacent polygons are neighbors
adjacency_red <- nb2mat(nb_red, style = "B", zero.policy = TRUE)
row.names(adjacency_red) <- NULL
image(adjacency_red)
#plot of Vietnam for all the regions
plot(st_geometry(geojson),
col = "steelblue", lwd = 0.5, asp = 1)
#plot of the regions of Vietnam in the training data
plot(st_geometry(geojson_reduced),
col = "steelblue", lwd = 0.5, asp = 1)
df_locs
geojson$NAME
geojson$NAME_1
df_locs
geojson$id
geojson_reduced <- geojson[geojson$id %in% df_locs, ]
nb_red <- poly2nb(geojson_reduced, queen = TRUE) #adjacent polygons are neighbors
adjacency_red <- nb2mat(nb_red, style = "B", zero.policy = TRUE)
row.names(adjacency_red) <- NULL
image(adjacency_red)
#plot of Vietnam for all the regions
plot(st_geometry(geojson),
col = "steelblue", lwd = 0.5, asp = 1)
#plot of the regions of Vietnam in the training data
plot(st_geometry(geojson_reduced),
col = "steelblue", lwd = 0.5, asp = 1)
df = read.csv(future_fn)
df <- mutate(df, ID_year = ID_year - min(df$ID_year) + 1)
#adding a counting variable for the months like 1, ..., 12, 13, ...
#could also do years*12 + months, but fails for weeks
df <-group_by(df, location) |>
mutate(month_num = row_number())
df = read.csv(future_fn)
#adding a counting variable for the months like 1, ..., 12, 13, ...
#could also do years*12 + months, but fails for weeks
df <-group_by(df, location) |>
mutate(month_num = row_number())
basis_meantemperature <- crossbasis(df$meantemperature, lag=3,
argvar = list(fun = "ns", knots = equalknots(df$meantemperature, 2)),
arglag = list(fun = "ns", knots = 3/2), group = df$ID_spat)
View(df)
source("train.R")
source("predict.R")
#test with data from Vietnam with a graph
train_chap("example_data_Viet/trainData.csv", "model")
predict_chap("model", "example_data_Viet/historic_data.csv", "example_data_Viet/future_data.csv", "example_data_Viet/predictions.csv", "example_data_Viet/vietnam.json")
source("predict.R")
#test with data from Vietnam with a graph
train_chap("example_data_Viet/trainData.csv", "model")
predict_chap("model", "example_data_Viet/historic_data.csv", "example_data_Viet/future_data.csv", "example_data_Viet/predictions.csv", "example_data_Viet/vietnam.json")
